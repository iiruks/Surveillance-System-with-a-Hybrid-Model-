{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28179f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.49 ðŸš€ Python-3.10.9 torch-2.5.1 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=ucf_dataset.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=ucf_project, name=yolo_ucf_train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=ucf_project/yolo_ucf_train2\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    754237  ultralytics.nn.modules.head.Detect           [15, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3,013,773 parameters, 3,013,757 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ucf_project/yolo_ucf_train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/rukmini/Documents/Project/newdata/reduced_train/Abuse.cac\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/rukmini/Documents/Project/newdata/reduced_test/Abuse.cache.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to ucf_project/yolo_ucf_train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mucf_project/yolo_ucf_train2\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G     0.3166      2.002      1.089         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        557        557      0.431      0.183      0.124      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G     0.1248      1.092     0.9241         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        557        557      0.433      0.197      0.144      0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G    0.09381     0.9356     0.9131         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        557        557       0.41      0.198       0.18      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 9.849 hours.\n",
      "Optimizer stripped from ucf_project/yolo_ucf_train2/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from ucf_project/yolo_ucf_train2/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating ucf_project/yolo_ucf_train2/weights/best.pt...\n",
      "Ultralytics 8.3.49 ðŸš€ Python-3.10.9 torch-2.5.1 CPU (Apple M2)\n",
      "Model summary (fused): 168 layers, 3,008,573 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        557        557      0.409      0.198      0.181       0.18\n",
      "         RoadAccidents         14         14          0          0     0.0611     0.0584\n",
      "                 Arson         15         15      0.155        0.4      0.358      0.358\n",
      "           Shoplifting         41         41       0.69      0.217      0.381      0.379\n",
      "              Stealing          3          3     0.0181      0.333      0.028      0.028\n",
      "              Burglary         42         42        0.2       0.31      0.244      0.244\n",
      "          NormalVideos        324        324       0.58          1      0.844      0.844\n",
      "              Fighting          4          4          0          0    0.00919    0.00919\n",
      "             Vandalism          6          6          1          0     0.0369     0.0369\n",
      "             Explosion         31         31          1          0      0.194      0.189\n",
      "                Arrest         17         17     0.0766      0.176      0.153      0.151\n",
      "                 Abuse          1          1          0          0    0.00575    0.00575\n",
      "               Robbery          3          3     0.0117      0.333     0.0192     0.0192\n",
      "               Assault         14         14          1          0     0.0582     0.0552\n",
      "           Abuse.cache         42         42          1          0      0.146      0.144\n",
      "Speed: 2.1ms preprocess, 287.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mucf_project/yolo_ucf_train2\u001b[0m\n",
      "Ultralytics 8.3.49 ðŸš€ Python-3.10.9 torch-2.5.1 CPU (Apple M2)\n",
      "Model summary (fused): 168 layers, 3,008,573 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/rukmini/Documents/Project/newdata/reduced_test/Abuse.cache.\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        557        557      0.409      0.198      0.181       0.18\n",
      "         RoadAccidents         14         14          0          0     0.0611     0.0584\n",
      "                 Arson         15         15      0.155        0.4      0.358      0.358\n",
      "           Shoplifting         41         41       0.69      0.217      0.381      0.379\n",
      "              Stealing          3          3     0.0181      0.333      0.028      0.028\n",
      "              Burglary         42         42        0.2       0.31      0.244      0.244\n",
      "          NormalVideos        324        324       0.58          1      0.844      0.844\n",
      "              Fighting          4          4          0          0    0.00919    0.00919\n",
      "             Vandalism          6          6          1          0     0.0369     0.0369\n",
      "             Explosion         31         31          1          0      0.194      0.189\n",
      "                Arrest         17         17     0.0766      0.176      0.153      0.151\n",
      "                 Abuse          1          1          0          0    0.00575    0.00575\n",
      "               Robbery          3          3     0.0117      0.333     0.0192     0.0192\n",
      "               Assault         14         14          1          0     0.0582     0.0552\n",
      "           Abuse.cache         42         42          1          0      0.146      0.144\n",
      "Speed: 1.8ms preprocess, 343.8ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mucf_project/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents019_x264_140.png: 640x640 1 NormalVideos, 101.3ms\n",
      "Speed: 2.0ms preprocess, 101.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents124_x264_40.png: 640x640 1 NormalVideos, 89.5ms\n",
      "Speed: 2.3ms preprocess, 89.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents123_x264_1000.png: 640x640 2 NormalVideoss, 126.6ms\n",
      "Speed: 2.0ms preprocess, 126.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents121_x264_1790.png: 640x640 1 NormalVideos, 209.8ms\n",
      "Speed: 4.9ms preprocess, 209.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train24\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents011_x264_950.png: 640x640 1 NormalVideos, 223.9ms\n",
      "Speed: 11.6ms preprocess, 223.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train25\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents012_x264_430.png: 640x640 1 NormalVideos, 235.4ms\n",
      "Speed: 5.5ms preprocess, 235.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train26\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents016_x264_1390.png: 640x640 1 NormalVideos, 271.4ms\n",
      "Speed: 7.0ms preprocess, 271.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train27\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents001_x264_150.png: 640x640 1 NormalVideos, 337.2ms\n",
      "Speed: 8.2ms preprocess, 337.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train28\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents132_x264_630.png: 640x640 1 NormalVideos, 337.3ms\n",
      "Speed: 7.3ms preprocess, 337.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train29\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents019_x264_850.png: 640x640 1 NormalVideos, 307.0ms\n",
      "Speed: 3.4ms preprocess, 307.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train210\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents016_x264_790.png: 640x640 1 NormalVideos, 288.2ms\n",
      "Speed: 4.8ms preprocess, 288.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train211\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents127_x264_420.png: 640x640 1 NormalVideos, 375.8ms\n",
      "Speed: 4.3ms preprocess, 375.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train212\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents016_x264_1170.png: 640x640 1 NormalVideos, 294.6ms\n",
      "Speed: 5.0ms preprocess, 294.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train213\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/RoadAccidents/RoadAccidents132_x264_440.png: 640x640 1 NormalVideos, 304.7ms\n",
      "Speed: 10.0ms preprocess, 304.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/RoadAccidents/yolo_ucf_train214\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson041_x264_2520.png: 640x640 1 NormalVideos, 211.9ms\n",
      "Speed: 3.1ms preprocess, 211.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson022_x264_6870.png: 640x640 1 NormalVideos, 229.4ms\n",
      "Speed: 3.0ms preprocess, 229.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson007_x264_1380.png: 640x640 1 NormalVideos, 193.6ms\n",
      "Speed: 8.0ms preprocess, 193.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson010_x264_1590.png: 640x640 1 NormalVideos, 203.0ms\n",
      "Speed: 2.9ms preprocess, 203.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train24\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson007_x264_3200.png: 640x640 2 NormalVideoss, 190.9ms\n",
      "Speed: 5.1ms preprocess, 190.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train25\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson041_x264_2820.png: 640x640 1 NormalVideos, 173.0ms\n",
      "Speed: 3.6ms preprocess, 173.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train26\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson022_x264_4470.png: 640x640 2 NormalVideoss, 157.3ms\n",
      "Speed: 43.8ms preprocess, 157.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train27\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson007_x264_750.png: 640x640 (no detections), 205.7ms\n",
      "Speed: 8.5ms preprocess, 205.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train28\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson022_x264_5350.png: 640x640 2 NormalVideoss, 162.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 3.3ms preprocess, 162.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train29\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson007_x264_4740.png: 640x640 2 NormalVideoss, 188.2ms\n",
      "Speed: 9.5ms preprocess, 188.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train210\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson041_x264_1860.png: 640x640 1 NormalVideos, 166.6ms\n",
      "Speed: 3.9ms preprocess, 166.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train211\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson022_x264_2920.png: 640x640 2 NormalVideoss, 160.8ms\n",
      "Speed: 2.8ms preprocess, 160.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train212\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson022_x264_7870.png: 640x640 1 NormalVideos, 182.1ms\n",
      "Speed: 3.4ms preprocess, 182.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train213\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson022_x264_2710.png: 640x640 2 NormalVideoss, 238.1ms\n",
      "Speed: 4.3ms preprocess, 238.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train214\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arson/Arson022_x264_870.png: 640x640 2 NormalVideoss, 164.1ms\n",
      "Speed: 3.5ms preprocess, 164.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arson/yolo_ucf_train215\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting049_x264_1000.png: 640x640 1 NormalVideos, 221.5ms\n",
      "Speed: 10.2ms preprocess, 221.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting010_x264_2490.png: 640x640 1 NormalVideos, 219.0ms\n",
      "Speed: 8.1ms preprocess, 219.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting033_x264_860.png: 640x640 1 NormalVideos, 172.3ms\n",
      "Speed: 3.2ms preprocess, 172.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting007_x264_2530.png: 640x640 1 NormalVideos, 245.9ms\n",
      "Speed: 3.5ms preprocess, 245.9ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train24\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting016_x264_520.png: 640x640 1 NormalVideos, 195.3ms\n",
      "Speed: 2.8ms preprocess, 195.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train25\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting049_x264_150.png: 640x640 1 NormalVideos, 174.3ms\n",
      "Speed: 3.4ms preprocess, 174.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train26\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting029_x264_760.png: 640x640 1 NormalVideos, 230.4ms\n",
      "Speed: 3.5ms preprocess, 230.4ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train27\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting001_x264_1800.png: 640x640 1 NormalVideos, 184.4ms\n",
      "Speed: 11.3ms preprocess, 184.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train28\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting033_x264_330.png: 640x640 1 NormalVideos, 235.4ms\n",
      "Speed: 5.8ms preprocess, 235.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train29\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting034_x264_1570.png: 640x640 1 NormalVideos, 124.5ms\n",
      "Speed: 10.3ms preprocess, 124.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train210\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting044_x264_12270.png: 640x640 1 NormalVideos, 209.4ms\n",
      "Speed: 3.1ms preprocess, 209.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train211\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting027_x264_1560.png: 640x640 1 NormalVideos, 135.3ms\n",
      "Speed: 3.1ms preprocess, 135.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train212\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting004_x264_1310.png: 640x640 1 NormalVideos, 193.5ms\n",
      "Speed: 8.7ms preprocess, 193.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train213\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting004_x264_5160.png: 640x640 1 NormalVideos, 198.7ms\n",
      "Speed: 2.7ms preprocess, 198.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train214\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting039_x264_1500.png: 640x640 1 NormalVideos, 164.8ms\n",
      "Speed: 3.0ms preprocess, 164.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train215\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting044_x264_5470.png: 640x640 1 NormalVideos, 209.1ms\n",
      "Speed: 6.6ms preprocess, 209.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train216\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting027_x264_1180.png: 640x640 1 NormalVideos, 163.9ms\n",
      "Speed: 3.1ms preprocess, 163.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train217\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting029_x264_1870.png: 640x640 1 NormalVideos, 280.2ms\n",
      "Speed: 8.1ms preprocess, 280.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train218\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting044_x264_7450.png: 640x640 1 NormalVideos, 146.4ms\n",
      "Speed: 6.8ms preprocess, 146.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train219\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting034_x264_1180.png: 640x640 1 NormalVideos, 237.1ms\n",
      "Speed: 4.7ms preprocess, 237.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train220\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting037_x264_180.png: 640x640 1 NormalVideos, 229.6ms\n",
      "Speed: 11.4ms preprocess, 229.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train221\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting027_x264_1140.png: 640x640 1 NormalVideos, 136.3ms\n",
      "Speed: 3.3ms preprocess, 136.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train222\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting004_x264_2990.png: 640x640 1 NormalVideos, 252.8ms\n",
      "Speed: 3.8ms preprocess, 252.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train223\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting016_x264_990.png: 640x640 1 NormalVideos, 207.9ms\n",
      "Speed: 10.4ms preprocess, 207.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train224\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting005_x264_560.png: 640x640 1 NormalVideos, 166.9ms\n",
      "Speed: 9.3ms preprocess, 166.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train225\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting044_x264_3340.png: 640x640 1 NormalVideos, 177.1ms\n",
      "Speed: 3.2ms preprocess, 177.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train226\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting044_x264_4980.png: 640x640 1 NormalVideos, 255.8ms\n",
      "Speed: 9.4ms preprocess, 255.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train227\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting021_x264_2860.png: 640x640 1 NormalVideos, 176.2ms\n",
      "Speed: 6.1ms preprocess, 176.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train228\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting034_x264_5490.png: 640x640 1 NormalVideos, 195.3ms\n",
      "Speed: 3.2ms preprocess, 195.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train229\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting044_x264_4940.png: 640x640 1 NormalVideos, 188.8ms\n",
      "Speed: 2.9ms preprocess, 188.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train230\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting037_x264_1050.png: 640x640 1 NormalVideos, 171.3ms\n",
      "Speed: 3.4ms preprocess, 171.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train231\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting044_x264_10180.png: 640x640 1 NormalVideos, 201.4ms\n",
      "Speed: 3.2ms preprocess, 201.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train232\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting004_x264_3580.png: 640x640 1 NormalVideos, 223.5ms\n",
      "Speed: 3.0ms preprocess, 223.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train233\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting039_x264_2460.png: 640x640 1 NormalVideos, 159.7ms\n",
      "Speed: 3.5ms preprocess, 159.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train234\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting001_x264_2240.png: 640x640 1 NormalVideos, 210.8ms\n",
      "Speed: 6.8ms preprocess, 210.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train235\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting044_x264_7960.png: 640x640 1 NormalVideos, 206.0ms\n",
      "Speed: 3.1ms preprocess, 206.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train236\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting020_x264_4700.png: 640x640 1 NormalVideos, 146.3ms\n",
      "Speed: 3.3ms preprocess, 146.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train237\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting007_x264_1020.png: 640x640 1 NormalVideos, 190.7ms\n",
      "Speed: 6.9ms preprocess, 190.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train238\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting007_x264_2460.png: 640x640 1 NormalVideos, 165.8ms\n",
      "Speed: 4.2ms preprocess, 165.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train239\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting044_x264_5180.png: 640x640 1 NormalVideos, 178.2ms\n",
      "Speed: 14.7ms preprocess, 178.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train240\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shoplifting/Shoplifting044_x264_11270.png: 640x640 1 NormalVideos, 163.3ms\n",
      "Speed: 4.9ms preprocess, 163.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shoplifting/yolo_ucf_train241\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Stealing/Stealing062_x264_500.png: 640x640 1 NormalVideos, 159.7ms\n",
      "Speed: 3.6ms preprocess, 159.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Stealing/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Stealing/Stealing036_x264_1620.png: 640x640 1 NormalVideos, 211.0ms\n",
      "Speed: 5.2ms preprocess, 211.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Stealing/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Stealing/Stealing019_x264_4120.png: 640x640 1 NormalVideos, 161.2ms\n",
      "Speed: 7.0ms preprocess, 161.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Stealing/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary032_x264_10880.png: 640x640 1 NormalVideos, 195.6ms\n",
      "Speed: 7.7ms preprocess, 195.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary061_x264_6920.png: 640x640 1 NormalVideos, 194.7ms\n",
      "Speed: 2.8ms preprocess, 194.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary079_x264_9070.png: 640x640 1 NormalVideos, 167.7ms\n",
      "Speed: 7.9ms preprocess, 167.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary079_x264_1360.png: 640x640 1 NormalVideos, 204.5ms\n",
      "Speed: 2.7ms preprocess, 204.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train24\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary032_x264_1220.png: 640x640 1 NormalVideos, 343.1ms\n",
      "Speed: 8.3ms preprocess, 343.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train25\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary076_x264_9620.png: 640x640 1 NormalVideos, 305.6ms\n",
      "Speed: 10.8ms preprocess, 305.6ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train26\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary076_x264_10120.png: 640x640 1 NormalVideos, 200.8ms\n",
      "Speed: 7.3ms preprocess, 200.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train27\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary076_x264_5190.png: 640x640 1 NormalVideos, 352.1ms\n",
      "Speed: 13.8ms preprocess, 352.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train28\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary061_x264_810.png: 640x640 1 NormalVideos, 320.7ms\n",
      "Speed: 9.4ms preprocess, 320.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train29\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary079_x264_5470.png: 640x640 1 NormalVideos, 306.5ms\n",
      "Speed: 3.8ms preprocess, 306.5ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train210\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary032_x264_12300.png: 640x640 1 NormalVideos, 282.8ms\n",
      "Speed: 7.8ms preprocess, 282.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train211\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary076_x264_8060.png: 640x640 1 NormalVideos, 235.9ms\n",
      "Speed: 5.6ms preprocess, 235.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train212\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary035_x264_2930.png: 640x640 1 NormalVideos, 220.1ms\n",
      "Speed: 7.2ms preprocess, 220.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train213\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary032_x264_14930.png: 640x640 1 NormalVideos, 215.7ms\n",
      "Speed: 7.5ms preprocess, 215.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train214\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary033_x264_280.png: 640x640 1 NormalVideos, 242.0ms\n",
      "Speed: 3.4ms preprocess, 242.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train215\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary032_x264_7030.png: 640x640 1 NormalVideos, 222.6ms\n",
      "Speed: 4.9ms preprocess, 222.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train216\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary076_x264_6010.png: 640x640 1 NormalVideos, 254.4ms\n",
      "Speed: 3.9ms preprocess, 254.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train217\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary005_x264_6980.png: 640x640 1 NormalVideos, 145.7ms\n",
      "Speed: 7.9ms preprocess, 145.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train218\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary079_x264_14040.png: 640x640 1 NormalVideos, 183.2ms\n",
      "Speed: 3.8ms preprocess, 183.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train219\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary076_x264_11890.png: 640x640 1 NormalVideos, 188.7ms\n",
      "Speed: 10.6ms preprocess, 188.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train220\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary076_x264_10540.png: 640x640 1 NormalVideos, 186.2ms\n",
      "Speed: 4.5ms preprocess, 186.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train221\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary024_x264_1100.png: 640x640 1 NormalVideos, 209.6ms\n",
      "Speed: 6.4ms preprocess, 209.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train222\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary021_x264_440.png: 640x640 1 NormalVideos, 172.8ms\n",
      "Speed: 3.5ms preprocess, 172.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train223\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary005_x264_7280.png: 640x640 1 NormalVideos, 168.4ms\n",
      "Speed: 3.2ms preprocess, 168.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train224\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary076_x264_10160.png: 640x640 1 NormalVideos, 221.4ms\n",
      "Speed: 2.8ms preprocess, 221.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train225\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary032_x264_4090.png: 640x640 1 NormalVideos, 151.5ms\n",
      "Speed: 6.6ms preprocess, 151.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train226\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary033_x264_100.png: 640x640 1 NormalVideos, 204.8ms\n",
      "Speed: 4.3ms preprocess, 204.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train227\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary035_x264_2590.png: 640x640 1 NormalVideos, 210.7ms\n",
      "Speed: 5.4ms preprocess, 210.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train228\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary061_x264_2090.png: 640x640 1 NormalVideos, 221.7ms\n",
      "Speed: 3.2ms preprocess, 221.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train229\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary079_x264_3680.png: 640x640 1 NormalVideos, 347.4ms\n",
      "Speed: 6.7ms preprocess, 347.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train230\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary005_x264_7270.png: 640x640 1 NormalVideos, 214.9ms\n",
      "Speed: 6.2ms preprocess, 214.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train231\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary079_x264_2400.png: 640x640 1 NormalVideos, 178.2ms\n",
      "Speed: 6.6ms preprocess, 178.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train232\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary024_x264_2760.png: 640x640 1 NormalVideos, 193.1ms\n",
      "Speed: 4.0ms preprocess, 193.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train233\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary037_x264_1730.png: 640x640 1 NormalVideos, 222.4ms\n",
      "Speed: 5.6ms preprocess, 222.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train234\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary005_x264_4620.png: 640x640 1 NormalVideos, 198.6ms\n",
      "Speed: 6.9ms preprocess, 198.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train235\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary005_x264_5460.png: 640x640 1 NormalVideos, 152.5ms\n",
      "Speed: 10.0ms preprocess, 152.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train236\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary061_x264_8180.png: 640x640 1 NormalVideos, 198.2ms\n",
      "Speed: 5.4ms preprocess, 198.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train237\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary076_x264_1470.png: 640x640 1 NormalVideos, 198.6ms\n",
      "Speed: 3.1ms preprocess, 198.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train238\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary005_x264_7370.png: 640x640 1 NormalVideos, 166.6ms\n",
      "Speed: 2.8ms preprocess, 166.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train239\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary005_x264_6050.png: 640x640 1 NormalVideos, 172.0ms\n",
      "Speed: 2.8ms preprocess, 172.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train240\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary079_x264_3630.png: 640x640 1 NormalVideos, 168.1ms\n",
      "Speed: 2.9ms preprocess, 168.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train241\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Burglary/Burglary061_x264_8860.png: 640x640 1 NormalVideos, 206.3ms\n",
      "Speed: 3.7ms preprocess, 206.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Burglary/yolo_ucf_train242\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_944_x264_6160.png: 640x640 1 NormalVideos, 181.4ms\n",
      "Speed: 3.1ms preprocess, 181.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_902_x264_80.png: 640x640 1 NormalVideos, 174.2ms\n",
      "Speed: 3.3ms preprocess, 174.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_87210.png: 640x640 1 NormalVideos, 194.8ms\n",
      "Speed: 8.2ms preprocess, 194.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_360_x264_940.png: 640x640 1 NormalVideos, 163.2ms\n",
      "Speed: 11.9ms preprocess, 163.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train24\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_34050.png: 640x640 1 NormalVideos, 138.5ms\n",
      "Speed: 3.8ms preprocess, 138.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train25\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_933_x264_1620.png: 640x640 1 NormalVideos, 210.7ms\n",
      "Speed: 3.8ms preprocess, 210.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train26\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_686_x264_1470.png: 640x640 1 NormalVideos, 184.2ms\n",
      "Speed: 3.9ms preprocess, 184.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train27\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_782_x264_1400.png: 640x640 1 NormalVideos, 197.5ms\n",
      "Speed: 2.7ms preprocess, 197.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train28\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_23470.png: 640x640 1 NormalVideos, 196.2ms\n",
      "Speed: 5.0ms preprocess, 196.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train29\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_722_x264_6240.png: 640x640 1 NormalVideos, 175.1ms\n",
      "Speed: 16.3ms preprocess, 175.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train210\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_882_x264_750.png: 640x640 1 NormalVideos, 197.8ms\n",
      "Speed: 2.8ms preprocess, 197.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train211\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_1950.png: 640x640 1 NormalVideos, 180.4ms\n",
      "Speed: 3.0ms preprocess, 180.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train212\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_722_x264_5990.png: 640x640 1 NormalVideos, 160.5ms\n",
      "Speed: 9.1ms preprocess, 160.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train213\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_49870.png: 640x640 1 NormalVideos, 198.6ms\n",
      "Speed: 3.5ms preprocess, 198.6ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train214\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_866_x264_500.png: 640x640 1 NormalVideos, 206.9ms\n",
      "Speed: 3.3ms preprocess, 206.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train215\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_903_x264_10.png: 640x640 1 NormalVideos, 160.6ms\n",
      "Speed: 3.9ms preprocess, 160.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train216\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_025_x264_520.png: 640x640 1 NormalVideos, 217.7ms\n",
      "Speed: 10.2ms preprocess, 217.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train217\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_15540.png: 640x640 1 NormalVideos, 160.8ms\n",
      "Speed: 2.9ms preprocess, 160.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train218\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_783_x264_7650.png: 640x640 1 NormalVideos, 160.5ms\n",
      "Speed: 3.4ms preprocess, 160.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train219\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_603_x264_2610.png: 640x640 1 NormalVideos, 185.2ms\n",
      "Speed: 4.0ms preprocess, 185.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train220\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_246_x264_1240.png: 640x640 1 NormalVideos, 172.4ms\n",
      "Speed: 3.2ms preprocess, 172.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train221\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_027_x264_2760.png: 640x640 1 NormalVideos, 194.2ms\n",
      "Speed: 2.9ms preprocess, 194.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train222\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_98680.png: 640x640 1 NormalVideos, 204.3ms\n",
      "Speed: 3.2ms preprocess, 204.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train223\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_64880.png: 640x640 1 NormalVideos, 156.7ms\n",
      "Speed: 3.2ms preprocess, 156.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train224\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_65220.png: 640x640 1 NormalVideos, 223.0ms\n",
      "Speed: 3.5ms preprocess, 223.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train225\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_46200.png: 640x640 1 NormalVideos, 151.5ms\n",
      "Speed: 8.0ms preprocess, 151.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train226\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_931_x264_1600.png: 640x640 1 NormalVideos, 198.1ms\n",
      "Speed: 3.2ms preprocess, 198.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train227\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_32740.png: 640x640 1 NormalVideos, 202.1ms\n",
      "Speed: 5.8ms preprocess, 202.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train228\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_28750.png: 640x640 1 NormalVideos, 151.6ms\n",
      "Speed: 4.7ms preprocess, 151.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train229\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_90430.png: 640x640 1 NormalVideos, 220.7ms\n",
      "Speed: 4.9ms preprocess, 220.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train230\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_882_x264_1560.png: 640x640 1 NormalVideos, 168.3ms\n",
      "Speed: 2.7ms preprocess, 168.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train231\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_939_x264_560.png: 640x640 1 NormalVideos, 160.2ms\n",
      "Speed: 3.1ms preprocess, 160.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train232\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_12650.png: 640x640 1 NormalVideos, 196.7ms\n",
      "Speed: 9.0ms preprocess, 196.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train233\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_898_x264_100.png: 640x640 1 NormalVideos, 184.2ms\n",
      "Speed: 12.9ms preprocess, 184.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train234\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_22630.png: 640x640 1 NormalVideos, 310.5ms\n",
      "Speed: 3.9ms preprocess, 310.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train235\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_352_x264_2890.png: 640x640 1 NormalVideos, 326.3ms\n",
      "Speed: 7.7ms preprocess, 326.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train236\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_84280.png: 640x640 1 NormalVideos, 316.3ms\n",
      "Speed: 4.0ms preprocess, 316.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train237\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_453_x264_1820.png: 640x640 1 NormalVideos, 311.5ms\n",
      "Speed: 3.3ms preprocess, 311.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train238\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_43730.png: 640x640 1 NormalVideos, 332.5ms\n",
      "Speed: 3.1ms preprocess, 332.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train239\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_87920.png: 640x640 1 NormalVideos, 366.9ms\n",
      "Speed: 6.3ms preprocess, 366.9ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train240\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_247_x264_4680.png: 640x640 1 NormalVideos, 168.7ms\n",
      "Speed: 3.5ms preprocess, 168.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train241\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_68990.png: 640x640 1 NormalVideos, 216.3ms\n",
      "Speed: 3.0ms preprocess, 216.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train242\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_874_x264_1550.png: 640x640 1 NormalVideos, 161.8ms\n",
      "Speed: 5.4ms preprocess, 161.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train243\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_14640.png: 640x640 1 NormalVideos, 163.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 9.3ms preprocess, 163.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train244\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_24740.png: 640x640 1 NormalVideos, 172.3ms\n",
      "Speed: 3.5ms preprocess, 172.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train245\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_894_x264_170.png: 640x640 1 NormalVideos, 157.1ms\n",
      "Speed: 2.9ms preprocess, 157.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train246\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_895_x264_2290.png: 640x640 1 NormalVideos, 219.9ms\n",
      "Speed: 6.3ms preprocess, 219.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train247\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_634_x264_12910.png: 640x640 1 NormalVideos, 210.0ms\n",
      "Speed: 3.8ms preprocess, 210.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train248\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_66300.png: 640x640 1 NormalVideos, 205.5ms\n",
      "Speed: 4.2ms preprocess, 205.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train249\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_780_x264_410.png: 640x640 1 NormalVideos, 228.9ms\n",
      "Speed: 3.4ms preprocess, 228.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train250\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_224_x264_2580.png: 640x640 1 NormalVideos, 239.5ms\n",
      "Speed: 9.3ms preprocess, 239.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train251\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_702_x264_670.png: 640x640 1 NormalVideos, 232.8ms\n",
      "Speed: 7.6ms preprocess, 232.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train252\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_64660.png: 640x640 1 NormalVideos, 247.3ms\n",
      "Speed: 3.8ms preprocess, 247.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train253\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_53250.png: 640x640 1 NormalVideos, 302.0ms\n",
      "Speed: 3.9ms preprocess, 302.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train254\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_40210.png: 640x640 1 NormalVideos, 194.1ms\n",
      "Speed: 4.5ms preprocess, 194.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train255\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_783_x264_7330.png: 640x640 1 NormalVideos, 243.5ms\n",
      "Speed: 4.2ms preprocess, 243.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train256\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_051_x264_110.png: 640x640 1 NormalVideos, 234.9ms\n",
      "Speed: 8.2ms preprocess, 234.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train257\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_877_x264_3180.png: 640x640 1 NormalVideos, 196.6ms\n",
      "Speed: 9.7ms preprocess, 196.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train258\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_72160.png: 640x640 1 NormalVideos, 195.8ms\n",
      "Speed: 6.5ms preprocess, 195.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train259\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_175_x264_2180.png: 640x640 1 NormalVideos, 246.1ms\n",
      "Speed: 3.4ms preprocess, 246.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train260\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_926_x264_930.png: 640x640 1 NormalVideos, 225.8ms\n",
      "Speed: 4.7ms preprocess, 225.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train261\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_247_x264_7980.png: 640x640 1 NormalVideos, 162.7ms\n",
      "Speed: 4.6ms preprocess, 162.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train262\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_45790.png: 640x640 1 NormalVideos, 204.8ms\n",
      "Speed: 3.9ms preprocess, 204.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train263\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_41290.png: 640x640 1 NormalVideos, 151.4ms\n",
      "Speed: 5.6ms preprocess, 151.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train264\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_51790.png: 640x640 1 NormalVideos, 160.9ms\n",
      "Speed: 4.9ms preprocess, 160.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train265\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_77780.png: 640x640 1 NormalVideos, 208.3ms\n",
      "Speed: 4.1ms preprocess, 208.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train266\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_887_x264_2060.png: 640x640 1 NormalVideos, 198.4ms\n",
      "Speed: 3.1ms preprocess, 198.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train267\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_26960.png: 640x640 1 NormalVideos, 173.0ms\n",
      "Speed: 2.9ms preprocess, 173.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train268\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_453_x264_4590.png: 640x640 1 NormalVideos, 190.4ms\n",
      "Speed: 6.1ms preprocess, 190.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train269\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_576_x264_6770.png: 640x640 1 NormalVideos, 192.6ms\n",
      "Speed: 4.6ms preprocess, 192.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train270\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_641_x264_1160.png: 640x640 1 NormalVideos, 201.3ms\n",
      "Speed: 2.9ms preprocess, 201.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train271\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_247_x264_7610.png: 640x640 1 NormalVideos, 222.5ms\n",
      "Speed: 5.6ms preprocess, 222.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train272\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_929_x264_150.png: 640x640 1 NormalVideos, 202.2ms\n",
      "Speed: 4.6ms preprocess, 202.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train273\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_783_x264_9320.png: 640x640 1 NormalVideos, 229.3ms\n",
      "Speed: 4.3ms preprocess, 229.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train274\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_944_x264_3020.png: 640x640 1 NormalVideos, 217.4ms\n",
      "Speed: 3.6ms preprocess, 217.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train275\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_889_x264_0.png: 640x640 1 NormalVideos, 255.4ms\n",
      "Speed: 4.6ms preprocess, 255.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train276\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_050_x264_3960.png: 640x640 1 NormalVideos, 234.8ms\n",
      "Speed: 4.8ms preprocess, 234.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train277\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_8300.png: 640x640 1 NormalVideos, 244.2ms\n",
      "Speed: 3.0ms preprocess, 244.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train278\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_704_x264_820.png: 640x640 1 NormalVideos, 200.3ms\n",
      "Speed: 5.4ms preprocess, 200.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train279\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_059_x264_730.png: 640x640 1 NormalVideos, 215.2ms\n",
      "Speed: 31.6ms preprocess, 215.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train280\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_247_x264_6390.png: 640x640 1 NormalVideos, 236.2ms\n",
      "Speed: 5.2ms preprocess, 236.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train281\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_877_x264_5810.png: 640x640 1 NormalVideos, 210.2ms\n",
      "Speed: 3.6ms preprocess, 210.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train282\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_32230.png: 640x640 1 NormalVideos, 182.9ms\n",
      "Speed: 5.9ms preprocess, 182.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train283\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_21890.png: 640x640 1 NormalVideos, 168.7ms\n",
      "Speed: 3.0ms preprocess, 168.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train284\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_050_x264_1390.png: 640x640 1 NormalVideos, 184.6ms\n",
      "Speed: 11.1ms preprocess, 184.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train285\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_310_x264_1820.png: 640x640 1 NormalVideos, 163.2ms\n",
      "Speed: 3.7ms preprocess, 163.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train286\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_33310.png: 640x640 1 NormalVideos, 202.2ms\n",
      "Speed: 9.1ms preprocess, 202.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train287\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_018_x264_680.png: 640x640 1 NormalVideos, 189.3ms\n",
      "Speed: 2.9ms preprocess, 189.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train288\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_8700.png: 640x640 1 NormalVideos, 163.1ms\n",
      "Speed: 3.6ms preprocess, 163.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train289\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_246_x264_3620.png: 640x640 1 NormalVideos, 200.2ms\n",
      "Speed: 6.7ms preprocess, 200.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train290\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_027_x264_160.png: 640x640 1 NormalVideos, 204.0ms\n",
      "Speed: 2.7ms preprocess, 204.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train291\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_877_x264_2990.png: 640x640 1 NormalVideos, 169.4ms\n",
      "Speed: 6.3ms preprocess, 169.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train292\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_60850.png: 640x640 1 NormalVideos, 185.0ms\n",
      "Speed: 12.6ms preprocess, 185.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train293\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_634_x264_1040.png: 640x640 1 NormalVideos, 190.8ms\n",
      "Speed: 4.9ms preprocess, 190.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train294\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_634_x264_9420.png: 640x640 1 NormalVideos, 173.5ms\n",
      "Speed: 2.9ms preprocess, 173.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train295\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_41800.png: 640x640 1 NormalVideos, 204.0ms\n",
      "Speed: 3.2ms preprocess, 204.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train296\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_4040.png: 640x640 1 NormalVideos, 194.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 10.4ms preprocess, 194.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train297\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_10520.png: 640x640 1 NormalVideos, 173.0ms\n",
      "Speed: 3.6ms preprocess, 173.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train298\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_103890.png: 640x640 1 NormalVideos, 192.4ms\n",
      "Speed: 2.9ms preprocess, 192.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train299\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_64100.png: 640x640 1 NormalVideos, 218.4ms\n",
      "Speed: 5.1ms preprocess, 218.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2100\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_18430.png: 640x640 1 NormalVideos, 154.6ms\n",
      "Speed: 3.1ms preprocess, 154.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2101\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_44460.png: 640x640 1 NormalVideos, 256.7ms\n",
      "Speed: 2.8ms preprocess, 256.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2102\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_26680.png: 640x640 1 NormalVideos, 367.3ms\n",
      "Speed: 3.7ms preprocess, 367.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2103\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_104090.png: 640x640 1 NormalVideos, 369.6ms\n",
      "Speed: 15.7ms preprocess, 369.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2104\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_42070.png: 640x640 1 NormalVideos, 295.4ms\n",
      "Speed: 5.8ms preprocess, 295.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2105\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_478_x264_3860.png: 640x640 1 NormalVideos, 335.8ms\n",
      "Speed: 9.6ms preprocess, 335.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2106\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_16160.png: 640x640 1 NormalVideos, 337.4ms\n",
      "Speed: 3.4ms preprocess, 337.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2107\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_85770.png: 640x640 1 NormalVideos, 337.3ms\n",
      "Speed: 7.2ms preprocess, 337.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2108\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_91980.png: 640x640 1 NormalVideos, 178.1ms\n",
      "Speed: 13.4ms preprocess, 178.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2109\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_4500.png: 640x640 1 NormalVideos, 190.2ms\n",
      "Speed: 6.4ms preprocess, 190.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2110\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_875_x264_1100.png: 640x640 1 NormalVideos, 154.7ms\n",
      "Speed: 3.5ms preprocess, 154.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2111\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_36530.png: 640x640 1 NormalVideos, 198.8ms\n",
      "Speed: 9.0ms preprocess, 198.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2112\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_576_x264_7230.png: 640x640 1 NormalVideos, 202.1ms\n",
      "Speed: 3.2ms preprocess, 202.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2113\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_006_x264_190.png: 640x640 1 NormalVideos, 167.5ms\n",
      "Speed: 3.0ms preprocess, 167.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2114\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_63530.png: 640x640 1 NormalVideos, 179.4ms\n",
      "Speed: 5.0ms preprocess, 179.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2115\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_23060.png: 640x640 1 NormalVideos, 168.6ms\n",
      "Speed: 3.8ms preprocess, 168.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2116\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_13970.png: 640x640 1 NormalVideos, 173.5ms\n",
      "Speed: 46.4ms preprocess, 173.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2117\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_14530.png: 640x640 1 NormalVideos, 210.6ms\n",
      "Speed: 5.9ms preprocess, 210.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2118\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_352_x264_4500.png: 640x640 1 NormalVideos, 221.1ms\n",
      "Speed: 3.3ms preprocess, 221.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2119\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_16420.png: 640x640 1 NormalVideos, 163.3ms\n",
      "Speed: 4.8ms preprocess, 163.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2120\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_99210.png: 640x640 1 NormalVideos, 205.5ms\n",
      "Speed: 2.9ms preprocess, 205.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2121\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_7150.png: 640x640 1 NormalVideos, 198.2ms\n",
      "Speed: 3.3ms preprocess, 198.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2122\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_14130.png: 640x640 1 NormalVideos, 174.1ms\n",
      "Speed: 2.9ms preprocess, 174.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2123\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_104910.png: 640x640 1 NormalVideos, 158.2ms\n",
      "Speed: 3.5ms preprocess, 158.2ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2124\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_926_x264_1060.png: 640x640 1 NormalVideos, 139.0ms\n",
      "Speed: 4.2ms preprocess, 139.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2125\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_75020.png: 640x640 1 NormalVideos, 162.7ms\n",
      "Speed: 3.1ms preprocess, 162.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2126\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_16830.png: 640x640 1 NormalVideos, 198.1ms\n",
      "Speed: 5.7ms preprocess, 198.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2127\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_71440.png: 640x640 1 NormalVideos, 172.8ms\n",
      "Speed: 2.8ms preprocess, 172.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2128\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_89660.png: 640x640 1 NormalVideos, 179.8ms\n",
      "Speed: 46.5ms preprocess, 179.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2129\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_352_x264_1050.png: 640x640 1 NormalVideos, 177.5ms\n",
      "Speed: 2.9ms preprocess, 177.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2130\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_310_x264_1210.png: 640x640 1 NormalVideos, 165.4ms\n",
      "Speed: 4.9ms preprocess, 165.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2131\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_634_x264_6110.png: 640x640 1 NormalVideos, 191.1ms\n",
      "Speed: 2.6ms preprocess, 191.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2132\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_722_x264_1760.png: 640x640 1 NormalVideos, 188.9ms\n",
      "Speed: 3.3ms preprocess, 188.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2133\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_74000.png: 640x640 1 NormalVideos, 165.5ms\n",
      "Speed: 3.2ms preprocess, 165.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2134\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_870_x264_20.png: 640x640 1 NormalVideos, 185.9ms\n",
      "Speed: 2.9ms preprocess, 185.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2135\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_224_x264_6550.png: 640x640 1 NormalVideos, 203.1ms\n",
      "Speed: 4.9ms preprocess, 203.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2136\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_86080.png: 640x640 1 NormalVideos, 176.0ms\n",
      "Speed: 11.4ms preprocess, 176.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2137\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_722_x264_2730.png: 640x640 1 NormalVideos, 203.4ms\n",
      "Speed: 4.5ms preprocess, 203.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2138\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_902_x264_1370.png: 640x640 1 NormalVideos, 184.8ms\n",
      "Speed: 3.9ms preprocess, 184.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2139\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_40930.png: 640x640 1 NormalVideos, 138.8ms\n",
      "Speed: 3.4ms preprocess, 138.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2140\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_55390.png: 640x640 1 NormalVideos, 186.7ms\n",
      "Speed: 3.4ms preprocess, 186.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2141\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_937_x264_780.png: 640x640 1 NormalVideos, 229.4ms\n",
      "Speed: 3.1ms preprocess, 229.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2142\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_610.png: 640x640 1 NormalVideos, 186.3ms\n",
      "Speed: 2.9ms preprocess, 186.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2143\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_887_x264_1290.png: 640x640 1 NormalVideos, 181.5ms\n",
      "Speed: 6.6ms preprocess, 181.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2144\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_932_x264_1500.png: 640x640 1 NormalVideos, 176.1ms\n",
      "Speed: 4.9ms preprocess, 176.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2145\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_106250.png: 640x640 1 NormalVideos, 155.0ms\n",
      "Speed: 3.6ms preprocess, 155.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2146\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_783_x264_5550.png: 640x640 1 NormalVideos, 180.7ms\n",
      "Speed: 8.7ms preprocess, 180.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2147\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_1040.png: 640x640 1 NormalVideos, 168.4ms\n",
      "Speed: 3.3ms preprocess, 168.4ms inference, 33.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2148\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_246_x264_2260.png: 640x640 1 NormalVideos, 164.3ms\n",
      "Speed: 3.0ms preprocess, 164.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2149\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_92140.png: 640x640 1 NormalVideos, 186.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 2.9ms preprocess, 186.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2150\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_453_x264_4280.png: 640x640 1 NormalVideos, 223.3ms\n",
      "Speed: 3.4ms preprocess, 223.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2151\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_16180.png: 640x640 1 NormalVideos, 163.2ms\n",
      "Speed: 3.1ms preprocess, 163.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2152\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_196_x264_1990.png: 640x640 1 NormalVideos, 230.3ms\n",
      "Speed: 2.7ms preprocess, 230.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2153\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_203_x264_2030.png: 640x640 1 NormalVideos, 144.0ms\n",
      "Speed: 3.1ms preprocess, 144.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2154\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_63740.png: 640x640 1 NormalVideos, 182.6ms\n",
      "Speed: 3.4ms preprocess, 182.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2155\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_717_x264_1120.png: 640x640 1 NormalVideos, 217.2ms\n",
      "Speed: 3.4ms preprocess, 217.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2156\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_923_x264_13560.png: 640x640 1 NormalVideos, 158.5ms\n",
      "Speed: 4.6ms preprocess, 158.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2157\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_28720.png: 640x640 1 NormalVideos, 195.4ms\n",
      "Speed: 6.2ms preprocess, 195.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2158\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_6730.png: 640x640 1 NormalVideos, 199.6ms\n",
      "Speed: 4.2ms preprocess, 199.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2159\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_47620.png: 640x640 1 NormalVideos, 161.8ms\n",
      "Speed: 6.0ms preprocess, 161.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2160\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_81160.png: 640x640 1 NormalVideos, 199.4ms\n",
      "Speed: 3.6ms preprocess, 199.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2161\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_783_x264_5960.png: 640x640 1 NormalVideos, 199.1ms\n",
      "Speed: 9.1ms preprocess, 199.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2162\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_781_x264_890.png: 640x640 1 NormalVideos, 165.8ms\n",
      "Speed: 3.2ms preprocess, 165.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2163\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_50980.png: 640x640 1 NormalVideos, 246.4ms\n",
      "Speed: 5.8ms preprocess, 246.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2164\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_101330.png: 640x640 1 NormalVideos, 220.7ms\n",
      "Speed: 3.3ms preprocess, 220.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2165\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_8670.png: 640x640 1 NormalVideos, 156.7ms\n",
      "Speed: 7.6ms preprocess, 156.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2166\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_933_x264_1070.png: 640x640 1 NormalVideos, 163.7ms\n",
      "Speed: 10.3ms preprocess, 163.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2167\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_93520.png: 640x640 1 NormalVideos, 199.4ms\n",
      "Speed: 4.4ms preprocess, 199.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2168\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_182_x264_2300.png: 640x640 1 NormalVideos, 151.5ms\n",
      "Speed: 4.2ms preprocess, 151.5ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2169\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_874_x264_1500.png: 640x640 1 NormalVideos, 187.8ms\n",
      "Speed: 3.1ms preprocess, 187.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2170\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_894_x264_2190.png: 640x640 1 NormalVideos, 245.4ms\n",
      "Speed: 3.5ms preprocess, 245.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2171\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_656_x264_150.png: 640x640 1 NormalVideos, 205.1ms\n",
      "Speed: 3.6ms preprocess, 205.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2172\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_439_x264_2500.png: 640x640 1 NormalVideos, 325.1ms\n",
      "Speed: 7.1ms preprocess, 325.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2173\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_722_x264_6570.png: 640x640 1 NormalVideos, 341.6ms\n",
      "Speed: 14.8ms preprocess, 341.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2174\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_72620.png: 640x640 1 NormalVideos, 347.7ms\n",
      "Speed: 4.6ms preprocess, 347.7ms inference, 12.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2175\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_71360.png: 640x640 1 NormalVideos, 333.7ms\n",
      "Speed: 8.7ms preprocess, 333.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2176\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_452_x264_260.png: 640x640 1 NormalVideos, 301.0ms\n",
      "Speed: 8.1ms preprocess, 301.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2177\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_175_x264_6160.png: 640x640 1 NormalVideos, 372.6ms\n",
      "Speed: 4.1ms preprocess, 372.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2178\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_94170.png: 640x640 1 NormalVideos, 177.7ms\n",
      "Speed: 3.1ms preprocess, 177.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2179\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_886_x264_900.png: 640x640 1 NormalVideos, 205.8ms\n",
      "Speed: 3.9ms preprocess, 205.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2180\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_30880.png: 640x640 1 NormalVideos, 180.9ms\n",
      "Speed: 6.8ms preprocess, 180.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2181\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_923_x264_15120.png: 640x640 1 NormalVideos, 188.0ms\n",
      "Speed: 2.8ms preprocess, 188.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2182\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_884_x264_3260.png: 640x640 1 NormalVideos, 209.4ms\n",
      "Speed: 3.2ms preprocess, 209.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2183\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_760.png: 640x640 1 NormalVideos, 165.3ms\n",
      "Speed: 5.0ms preprocess, 165.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2184\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_247_x264_7910.png: 640x640 1 NormalVideos, 191.3ms\n",
      "Speed: 8.6ms preprocess, 191.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2185\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_22360.png: 640x640 1 NormalVideos, 272.9ms\n",
      "Speed: 3.8ms preprocess, 272.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2186\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_603_x264_1950.png: 640x640 1 NormalVideos, 216.8ms\n",
      "Speed: 4.3ms preprocess, 216.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2187\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_634_x264_3310.png: 640x640 1 NormalVideos, 156.4ms\n",
      "Speed: 3.1ms preprocess, 156.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2188\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_2180.png: 640x640 1 NormalVideos, 187.3ms\n",
      "Speed: 3.7ms preprocess, 187.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2189\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_780_x264_1070.png: 640x640 1 NormalVideos, 173.1ms\n",
      "Speed: 8.1ms preprocess, 173.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2190\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_8280.png: 640x640 1 NormalVideos, 170.3ms\n",
      "Speed: 3.6ms preprocess, 170.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2191\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_890_x264_1710.png: 640x640 1 NormalVideos, 226.0ms\n",
      "Speed: 8.1ms preprocess, 226.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2192\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_80950.png: 640x640 1 NormalVideos, 150.3ms\n",
      "Speed: 8.3ms preprocess, 150.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2193\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_923_x264_12920.png: 640x640 1 NormalVideos, 162.4ms\n",
      "Speed: 3.8ms preprocess, 162.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2194\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_48150.png: 640x640 1 NormalVideos, 199.8ms\n",
      "Speed: 3.0ms preprocess, 199.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2195\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_16560.png: 640x640 1 NormalVideos, 171.8ms\n",
      "Speed: 3.9ms preprocess, 171.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2196\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_930_x264_570.png: 640x640 1 NormalVideos, 205.2ms\n",
      "Speed: 5.9ms preprocess, 205.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2197\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_015_x264_80.png: 640x640 1 NormalVideos, 223.5ms\n",
      "Speed: 2.7ms preprocess, 223.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2198\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_641_x264_1290.png: 640x640 1 NormalVideos, 167.6ms\n",
      "Speed: 10.5ms preprocess, 167.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2199\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_13950.png: 640x640 1 NormalVideos, 229.8ms\n",
      "Speed: 2.6ms preprocess, 229.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2200\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_003_x264_1310.png: 640x640 1 NormalVideos, 227.9ms\n",
      "Speed: 5.5ms preprocess, 227.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2201\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_876_x264_200.png: 640x640 1 NormalVideos, 234.7ms\n",
      "Speed: 7.8ms preprocess, 234.7ms inference, 17.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2202\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_37140.png: 640x640 1 NormalVideos, 211.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 3.5ms preprocess, 211.1ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2203\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_18840.png: 640x640 1 NormalVideos, 241.6ms\n",
      "Speed: 3.2ms preprocess, 241.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2204\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_41510.png: 640x640 1 NormalVideos, 250.5ms\n",
      "Speed: 10.1ms preprocess, 250.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2205\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_196_x264_1020.png: 640x640 1 NormalVideos, 241.4ms\n",
      "Speed: 2.9ms preprocess, 241.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2206\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_003_x264_790.png: 640x640 1 NormalVideos, 170.2ms\n",
      "Speed: 3.1ms preprocess, 170.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2207\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_175_x264_7320.png: 640x640 1 NormalVideos, 220.8ms\n",
      "Speed: 3.9ms preprocess, 220.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2208\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_887_x264_4680.png: 640x640 1 NormalVideos, 194.6ms\n",
      "Speed: 8.2ms preprocess, 194.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2209\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_782_x264_3680.png: 640x640 1 NormalVideos, 169.5ms\n",
      "Speed: 3.3ms preprocess, 169.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2210\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_634_x264_6290.png: 640x640 1 NormalVideos, 186.0ms\n",
      "Speed: 12.2ms preprocess, 186.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2211\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_884_x264_8050.png: 640x640 1 NormalVideos, 166.7ms\n",
      "Speed: 3.0ms preprocess, 166.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2212\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_4330.png: 640x640 1 NormalVideos, 154.0ms\n",
      "Speed: 2.9ms preprocess, 154.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2213\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_289_x264_30.png: 640x640 1 NormalVideos, 208.1ms\n",
      "Speed: 3.2ms preprocess, 208.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2214\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_247_x264_1180.png: 640x640 1 NormalVideos, 175.0ms\n",
      "Speed: 2.8ms preprocess, 175.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2215\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_782_x264_2830.png: 640x640 1 NormalVideos, 198.1ms\n",
      "Speed: 3.1ms preprocess, 198.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2216\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_887_x264_3510.png: 640x640 1 NormalVideos, 196.4ms\n",
      "Speed: 3.6ms preprocess, 196.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2217\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_106890.png: 640x640 1 NormalVideos, 165.3ms\n",
      "Speed: 3.7ms preprocess, 165.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2218\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_55070.png: 640x640 1 NormalVideos, 205.3ms\n",
      "Speed: 4.5ms preprocess, 205.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2219\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_14950.png: 640x640 1 NormalVideos, 189.4ms\n",
      "Speed: 3.9ms preprocess, 189.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2220\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_62150.png: 640x640 1 NormalVideos, 136.6ms\n",
      "Speed: 4.0ms preprocess, 136.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2221\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_10520.png: 640x640 1 NormalVideos, 191.1ms\n",
      "Speed: 5.8ms preprocess, 191.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2222\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_876_x264_210.png: 640x640 1 NormalVideos, 151.5ms\n",
      "Speed: 8.5ms preprocess, 151.5ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2223\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_782_x264_3520.png: 640x640 1 NormalVideos, 165.8ms\n",
      "Speed: 69.6ms preprocess, 165.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2224\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_702_x264_140.png: 640x640 1 NormalVideos, 207.8ms\n",
      "Speed: 3.5ms preprocess, 207.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2225\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_14140.png: 640x640 1 NormalVideos, 178.6ms\n",
      "Speed: 3.1ms preprocess, 178.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2226\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_439_x264_3590.png: 640x640 1 NormalVideos, 156.4ms\n",
      "Speed: 37.6ms preprocess, 156.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2227\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_597_x264_1650.png: 640x640 1 NormalVideos, 190.7ms\n",
      "Speed: 2.7ms preprocess, 190.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2228\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_722_x264_5320.png: 640x640 1 NormalVideos, 172.3ms\n",
      "Speed: 3.1ms preprocess, 172.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2229\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_19480.png: 640x640 1 NormalVideos, 171.3ms\n",
      "Speed: 6.5ms preprocess, 171.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2230\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_182_x264_3580.png: 640x640 1 NormalVideos, 178.3ms\n",
      "Speed: 10.9ms preprocess, 178.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2231\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_710_x264_50.png: 640x640 1 NormalVideos, 172.4ms\n",
      "Speed: 3.7ms preprocess, 172.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2232\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_934_x264_350.png: 640x640 1 NormalVideos, 196.7ms\n",
      "Speed: 5.1ms preprocess, 196.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2233\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_10770.png: 640x640 1 NormalVideos, 204.5ms\n",
      "Speed: 4.9ms preprocess, 204.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2234\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_781_x264_1640.png: 640x640 1 NormalVideos, 158.1ms\n",
      "Speed: 4.2ms preprocess, 158.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2235\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_717_x264_590.png: 640x640 1 NormalVideos, 153.7ms\n",
      "Speed: 3.0ms preprocess, 153.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2236\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_20670.png: 640x640 1 NormalVideos, 164.2ms\n",
      "Speed: 3.1ms preprocess, 164.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2237\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_28760.png: 640x640 1 NormalVideos, 206.2ms\n",
      "Speed: 8.2ms preprocess, 206.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2238\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_050_x264_3830.png: 640x640 1 NormalVideos, 186.3ms\n",
      "Speed: 7.0ms preprocess, 186.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2239\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_439_x264_2920.png: 640x640 1 NormalVideos, 180.7ms\n",
      "Speed: 7.4ms preprocess, 180.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2240\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_38200.png: 640x640 1 NormalVideos, 151.6ms\n",
      "Speed: 44.1ms preprocess, 151.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2241\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_884_x264_880.png: 640x640 1 NormalVideos, 188.1ms\n",
      "Speed: 11.0ms preprocess, 188.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2242\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_104660.png: 640x640 1 NormalVideos, 316.8ms\n",
      "Speed: 3.2ms preprocess, 316.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2243\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_210_x264_4500.png: 640x640 1 NormalVideos, 335.9ms\n",
      "Speed: 3.5ms preprocess, 335.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2244\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_47890.png: 640x640 1 NormalVideos, 340.2ms\n",
      "Speed: 10.4ms preprocess, 340.2ms inference, 10.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2245\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_82500.png: 640x640 1 NormalVideos, 338.3ms\n",
      "Speed: 15.9ms preprocess, 338.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2246\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_33730.png: 640x640 1 NormalVideos, 159.7ms\n",
      "Speed: 9.8ms preprocess, 159.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2247\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_401_x264_920.png: 640x640 1 NormalVideos, 210.8ms\n",
      "Speed: 4.7ms preprocess, 210.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2248\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_926_x264_1080.png: 640x640 1 NormalVideos, 366.1ms\n",
      "Speed: 10.3ms preprocess, 366.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2249\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_453_x264_1870.png: 640x640 1 NormalVideos, 195.7ms\n",
      "Speed: 8.8ms preprocess, 195.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2250\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_27520.png: 640x640 1 NormalVideos, 176.9ms\n",
      "Speed: 2.7ms preprocess, 176.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2251\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_44780.png: 640x640 1 NormalVideos, 183.5ms\n",
      "Speed: 2.7ms preprocess, 183.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2252\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_875_x264_60.png: 640x640 1 NormalVideos, 187.5ms\n",
      "Speed: 3.9ms preprocess, 187.5ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2253\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_923_x264_2640.png: 640x640 1 NormalVideos, 168.4ms\n",
      "Speed: 8.4ms preprocess, 168.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2254\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_17030.png: 640x640 1 NormalVideos, 178.1ms\n",
      "Speed: 2.9ms preprocess, 178.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2255\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_941_x264_1190.png: 640x640 1 NormalVideos, 201.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 8.0ms preprocess, 201.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2256\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_20400.png: 640x640 1 NormalVideos, 158.5ms\n",
      "Speed: 4.1ms preprocess, 158.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2257\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_27420.png: 640x640 1 NormalVideos, 192.5ms\n",
      "Speed: 4.4ms preprocess, 192.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2258\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_19140.png: 640x640 1 NormalVideos, 204.4ms\n",
      "Speed: 2.9ms preprocess, 204.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2259\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_27150.png: 640x640 1 NormalVideos, 220.0ms\n",
      "Speed: 8.6ms preprocess, 220.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2260\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_783_x264_8350.png: 640x640 1 NormalVideos, 149.1ms\n",
      "Speed: 20.9ms preprocess, 149.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2261\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_48290.png: 640x640 1 NormalVideos, 188.9ms\n",
      "Speed: 6.4ms preprocess, 188.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2262\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_19430.png: 640x640 1 NormalVideos, 179.3ms\n",
      "Speed: 2.8ms preprocess, 179.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2263\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_923_x264_9660.png: 640x640 1 NormalVideos, 186.4ms\n",
      "Speed: 2.8ms preprocess, 186.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2264\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_365_x264_2340.png: 640x640 1 NormalVideos, 240.3ms\n",
      "Speed: 2.9ms preprocess, 240.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2265\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_24570.png: 640x640 1 NormalVideos, 246.2ms\n",
      "Speed: 3.1ms preprocess, 246.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2266\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_923_x264_8350.png: 640x640 1 NormalVideos, 208.0ms\n",
      "Speed: 3.1ms preprocess, 208.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2267\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_101590.png: 640x640 1 NormalVideos, 257.3ms\n",
      "Speed: 11.6ms preprocess, 257.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2268\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_84200.png: 640x640 1 NormalVideos, 253.9ms\n",
      "Speed: 6.1ms preprocess, 253.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2269\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_3980.png: 640x640 1 NormalVideos, 170.8ms\n",
      "Speed: 4.4ms preprocess, 170.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2270\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_104980.png: 640x640 1 NormalVideos, 171.6ms\n",
      "Speed: 5.5ms preprocess, 171.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2271\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_782_x264_3180.png: 640x640 1 NormalVideos, 181.7ms\n",
      "Speed: 3.3ms preprocess, 181.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2272\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_247_x264_4840.png: 640x640 1 NormalVideos, 202.5ms\n",
      "Speed: 3.2ms preprocess, 202.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2273\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_927_x264_910.png: 640x640 1 NormalVideos, 174.2ms\n",
      "Speed: 3.8ms preprocess, 174.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2274\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_923_x264_16110.png: 640x640 1 NormalVideos, 152.0ms\n",
      "Speed: 3.1ms preprocess, 152.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2275\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_27620.png: 640x640 1 NormalVideos, 190.4ms\n",
      "Speed: 3.0ms preprocess, 190.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2276\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_725_x264_460.png: 640x640 1 NormalVideos, 170.7ms\n",
      "Speed: 6.1ms preprocess, 170.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2277\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_783_x264_8150.png: 640x640 1 NormalVideos, 179.8ms\n",
      "Speed: 4.3ms preprocess, 179.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2278\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_175_x264_1690.png: 640x640 1 NormalVideos, 215.9ms\n",
      "Speed: 5.2ms preprocess, 215.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2279\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_224_x264_1720.png: 640x640 1 NormalVideos, 164.8ms\n",
      "Speed: 2.8ms preprocess, 164.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2280\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_686_x264_350.png: 640x640 1 NormalVideos, 201.6ms\n",
      "Speed: 8.8ms preprocess, 201.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2281\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_880_x264_6580.png: 640x640 1 NormalVideos, 191.1ms\n",
      "Speed: 2.9ms preprocess, 191.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2282\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_887_x264_6590.png: 640x640 1 NormalVideos, 161.3ms\n",
      "Speed: 9.4ms preprocess, 161.3ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2283\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_439_x264_3290.png: 640x640 1 NormalVideos, 195.1ms\n",
      "Speed: 4.2ms preprocess, 195.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2284\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_702_x264_1740.png: 640x640 1 NormalVideos, 196.6ms\n",
      "Speed: 3.2ms preprocess, 196.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2285\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_621_x264_870.png: 640x640 1 NormalVideos, 163.1ms\n",
      "Speed: 3.3ms preprocess, 163.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2286\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_175_x264_900.png: 640x640 1 NormalVideos, 200.8ms\n",
      "Speed: 3.8ms preprocess, 200.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2287\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_56650.png: 640x640 1 NormalVideos, 199.0ms\n",
      "Speed: 3.3ms preprocess, 199.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2288\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_938_x264_3290.png: 640x640 1 NormalVideos, 131.4ms\n",
      "Speed: 3.8ms preprocess, 131.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2289\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_417_x264_800.png: 640x640 1 NormalVideos, 167.7ms\n",
      "Speed: 3.6ms preprocess, 167.7ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2290\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_656_x264_1180.png: 640x640 1 NormalVideos, 218.8ms\n",
      "Speed: 2.9ms preprocess, 218.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2291\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_203_x264_140.png: 640x640 1 NormalVideos, 164.0ms\n",
      "Speed: 3.0ms preprocess, 164.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2292\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_61670.png: 640x640 1 NormalVideos, 230.5ms\n",
      "Speed: 3.3ms preprocess, 230.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2293\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_27240.png: 640x640 1 NormalVideos, 252.5ms\n",
      "Speed: 4.9ms preprocess, 252.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2294\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_722_x264_1520.png: 640x640 1 NormalVideos, 224.8ms\n",
      "Speed: 3.8ms preprocess, 224.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2295\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_352_x264_4630.png: 640x640 1 NormalVideos, 235.0ms\n",
      "Speed: 3.6ms preprocess, 235.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2296\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_247_x264_2170.png: 640x640 1 NormalVideos, 237.2ms\n",
      "Speed: 7.5ms preprocess, 237.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2297\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_884_x264_5890.png: 640x640 1 NormalVideos, 222.9ms\n",
      "Speed: 6.7ms preprocess, 222.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2298\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_14310.png: 640x640 1 NormalVideos, 153.5ms\n",
      "Speed: 3.2ms preprocess, 153.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2299\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_50490.png: 640x640 1 NormalVideos, 202.6ms\n",
      "Speed: 5.1ms preprocess, 202.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2300\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_621_x264_3550.png: 640x640 1 NormalVideos, 205.9ms\n",
      "Speed: 2.9ms preprocess, 205.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2301\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_9260.png: 640x640 1 NormalVideos, 207.7ms\n",
      "Speed: 4.0ms preprocess, 207.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2302\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_81690.png: 640x640 1 NormalVideos, 116.7ms\n",
      "Speed: 3.0ms preprocess, 116.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2303\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_97970.png: 640x640 1 NormalVideos, 192.7ms\n",
      "Speed: 5.6ms preprocess, 192.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2304\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_50080.png: 640x640 1 NormalVideos, 172.2ms\n",
      "Speed: 2.8ms preprocess, 172.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2305\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_901_x264_850.png: 640x640 1 NormalVideos, 185.4ms\n",
      "Speed: 3.5ms preprocess, 185.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2306\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_439_x264_250.png: 640x640 1 NormalVideos, 192.7ms\n",
      "Speed: 13.0ms preprocess, 192.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2307\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_941_x264_1220.png: 640x640 1 NormalVideos, 176.6ms\n",
      "Speed: 3.0ms preprocess, 176.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2308\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_92670.png: 640x640 1 NormalVideos, 192.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 3.5ms preprocess, 192.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2309\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_106760.png: 640x640 1 NormalVideos, 183.5ms\n",
      "Speed: 5.3ms preprocess, 183.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2310\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_79160.png: 640x640 1 NormalVideos, 169.5ms\n",
      "Speed: 2.9ms preprocess, 169.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2311\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_911_x264_280.png: 640x640 1 NormalVideos, 212.7ms\n",
      "Speed: 7.0ms preprocess, 212.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2312\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_634_x264_2860.png: 640x640 1 NormalVideos, 335.3ms\n",
      "Speed: 11.5ms preprocess, 335.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2313\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_39430.png: 640x640 1 NormalVideos, 328.5ms\n",
      "Speed: 8.5ms preprocess, 328.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2314\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_887_x264_430.png: 640x640 1 NormalVideos, 336.4ms\n",
      "Speed: 5.6ms preprocess, 336.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2315\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_58520.png: 640x640 1 NormalVideos, 301.2ms\n",
      "Speed: 4.1ms preprocess, 301.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2316\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_634_x264_6810.png: 640x640 1 NormalVideos, 339.4ms\n",
      "Speed: 14.8ms preprocess, 339.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2317\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_923_x264_15350.png: 640x640 1 NormalVideos, 330.8ms\n",
      "Speed: 3.0ms preprocess, 330.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2318\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_924_x264_22070.png: 640x640 1 NormalVideos, 228.3ms\n",
      "Speed: 8.3ms preprocess, 228.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2319\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_17550.png: 640x640 1 NormalVideos, 264.6ms\n",
      "Speed: 7.2ms preprocess, 264.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2320\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_940_x264_470.png: 640x640 1 NormalVideos, 228.4ms\n",
      "Speed: 21.8ms preprocess, 228.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2321\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_34920.png: 640x640 1 NormalVideos, 182.9ms\n",
      "Speed: 4.3ms preprocess, 182.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2322\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_935_x264_41830.png: 640x640 1 NormalVideos, 176.5ms\n",
      "Speed: 3.7ms preprocess, 176.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2323\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/NormalVideos/Normal_Videos_780_x264_590.png: 640x640 1 NormalVideos, 177.4ms\n",
      "Speed: 3.0ms preprocess, 177.4ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/NormalVideos/yolo_ucf_train2324\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Fighting/Fighting047_x264_1530.png: 640x640 1 NormalVideos, 174.6ms\n",
      "Speed: 3.5ms preprocess, 174.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Fighting/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Fighting/Fighting018_x264_920.png: 640x640 1 NormalVideos, 166.2ms\n",
      "Speed: 3.6ms preprocess, 166.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Fighting/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Fighting/Fighting047_x264_370.png: 640x640 1 NormalVideos, 193.0ms\n",
      "Speed: 3.6ms preprocess, 193.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Fighting/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Fighting/Fighting003_x264_290.png: 640x640 1 NormalVideos, 162.3ms\n",
      "Speed: 3.2ms preprocess, 162.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Fighting/yolo_ucf_train24\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Vandalism/Vandalism007_x264_1040.png: 640x640 1 NormalVideos, 183.1ms\n",
      "Speed: 16.9ms preprocess, 183.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Vandalism/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Vandalism/Vandalism036_x264_800.png: 640x640 1 NormalVideos, 199.4ms\n",
      "Speed: 6.8ms preprocess, 199.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Vandalism/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Vandalism/Vandalism036_x264_490.png: 640x640 1 NormalVideos, 252.6ms\n",
      "Speed: 8.8ms preprocess, 252.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Vandalism/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Vandalism/Vandalism028_x264_4190.png: 640x640 1 NormalVideos, 200.5ms\n",
      "Speed: 6.3ms preprocess, 200.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Vandalism/yolo_ucf_train24\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Vandalism/Vandalism017_x264_930.png: 640x640 1 NormalVideos, 244.7ms\n",
      "Speed: 3.2ms preprocess, 244.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Vandalism/yolo_ucf_train25\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Vandalism/Vandalism015_x264_1790.png: 640x640 1 NormalVideos, 228.5ms\n",
      "Speed: 3.8ms preprocess, 228.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Vandalism/yolo_ucf_train26\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion007_x264_5600.png: 640x640 1 NormalVideos, 226.1ms\n",
      "Speed: 4.4ms preprocess, 226.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion027_x264_300.png: 640x640 1 NormalVideos, 226.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 3.0ms preprocess, 226.4ms inference, 24.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion002_x264_2980.png: 640x640 1 NormalVideos, 185.0ms\n",
      "Speed: 3.7ms preprocess, 185.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion008_x264_410.png: 640x640 1 NormalVideos, 225.4ms\n",
      "Speed: 9.0ms preprocess, 225.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train24\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion016_x264_50.png: 640x640 1 NormalVideos, 240.8ms\n",
      "Speed: 4.4ms preprocess, 240.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train25\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion013_x264_2580.png: 640x640 1 NormalVideos, 236.0ms\n",
      "Speed: 2.9ms preprocess, 236.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train26\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion004_x264_1710.png: 640x640 1 NormalVideos, 133.2ms\n",
      "Speed: 3.3ms preprocess, 133.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train27\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion010_x264_510.png: 640x640 1 NormalVideos, 181.8ms\n",
      "Speed: 4.5ms preprocess, 181.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train28\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion008_x264_300.png: 640x640 1 NormalVideos, 181.5ms\n",
      "Speed: 3.3ms preprocess, 181.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train29\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion010_x264_950.png: 640x640 1 NormalVideos, 181.7ms\n",
      "Speed: 2.9ms preprocess, 181.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train210\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion007_x264_6970.png: 640x640 1 NormalVideos, 203.5ms\n",
      "Speed: 7.8ms preprocess, 203.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train211\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion022_x264_3120.png: 640x640 1 NormalVideos, 169.2ms\n",
      "Speed: 4.2ms preprocess, 169.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train212\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion036_x264_190.png: 640x640 1 NormalVideos, 190.4ms\n",
      "Speed: 3.3ms preprocess, 190.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train213\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion022_x264_3300.png: 640x640 1 NormalVideos, 189.4ms\n",
      "Speed: 3.9ms preprocess, 189.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train214\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion036_x264_20.png: 640x640 1 NormalVideos, 163.0ms\n",
      "Speed: 2.8ms preprocess, 163.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train215\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion036_x264_2190.png: 640x640 1 NormalVideos, 201.0ms\n",
      "Speed: 8.0ms preprocess, 201.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train216\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion007_x264_7720.png: 640x640 1 NormalVideos, 207.2ms\n",
      "Speed: 3.5ms preprocess, 207.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train217\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion004_x264_1750.png: 640x640 1 NormalVideos, 163.7ms\n",
      "Speed: 3.0ms preprocess, 163.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train218\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion016_x264_150.png: 640x640 1 NormalVideos, 201.1ms\n",
      "Speed: 4.8ms preprocess, 201.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train219\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion002_x264_40.png: 640x640 1 NormalVideos, 190.7ms\n",
      "Speed: 5.8ms preprocess, 190.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train220\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion007_x264_6170.png: 640x640 1 NormalVideos, 187.4ms\n",
      "Speed: 2.9ms preprocess, 187.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train221\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion007_x264_15780.png: 640x640 1 NormalVideos, 151.1ms\n",
      "Speed: 3.1ms preprocess, 151.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train222\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion043_x264_3860.png: 640x640 1 NormalVideos, 162.4ms\n",
      "Speed: 3.6ms preprocess, 162.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train223\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion027_x264_580.png: 640x640 1 NormalVideos, 199.1ms\n",
      "Speed: 3.6ms preprocess, 199.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train224\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion022_x264_2330.png: 640x640 1 NormalVideos, 184.5ms\n",
      "Speed: 6.2ms preprocess, 184.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train225\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion043_x264_530.png: 640x640 1 NormalVideos, 155.3ms\n",
      "Speed: 9.4ms preprocess, 155.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train226\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion011_x264_450.png: 640x640 1 NormalVideos, 188.7ms\n",
      "Speed: 4.7ms preprocess, 188.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train227\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion007_x264_930.png: 640x640 1 NormalVideos, 224.5ms\n",
      "Speed: 8.4ms preprocess, 224.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train228\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion008_x264_810.png: 640x640 1 NormalVideos, 184.8ms\n",
      "Speed: 3.4ms preprocess, 184.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train229\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion036_x264_930.png: 640x640 1 NormalVideos, 180.8ms\n",
      "Speed: 38.7ms preprocess, 180.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train230\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Explosion/Explosion028_x264_400.png: 640x640 1 NormalVideos, 177.7ms\n",
      "Speed: 5.1ms preprocess, 177.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Explosion/yolo_ucf_train231\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest039_x264_3210.png: 640x640 1 NormalVideos, 174.5ms\n",
      "Speed: 3.5ms preprocess, 174.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest039_x264_15750.png: 640x640 1 NormalVideos, 188.3ms\n",
      "Speed: 3.0ms preprocess, 188.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest039_x264_50.png: 640x640 1 NormalVideos, 205.6ms\n",
      "Speed: 2.8ms preprocess, 205.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest030_x264_4860.png: 640x640 1 NormalVideos, 166.4ms\n",
      "Speed: 3.9ms preprocess, 166.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train24\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest039_x264_12000.png: 640x640 1 NormalVideos, 192.5ms\n",
      "Speed: 3.8ms preprocess, 192.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train25\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest030_x264_5930.png: 640x640 1 NormalVideos, 160.6ms\n",
      "Speed: 4.1ms preprocess, 160.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train26\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest039_x264_5610.png: 640x640 1 NormalVideos, 139.8ms\n",
      "Speed: 18.6ms preprocess, 139.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train27\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest039_x264_9820.png: 640x640 1 NormalVideos, 195.5ms\n",
      "Speed: 24.7ms preprocess, 195.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train28\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest024_x264_620.png: 640x640 2 NormalVideoss, 209.3ms\n",
      "Speed: 8.6ms preprocess, 209.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train29\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest024_x264_1790.png: 640x640 2 NormalVideoss, 178.1ms\n",
      "Speed: 4.4ms preprocess, 178.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train210\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest007_x264_2370.png: 640x640 1 NormalVideos, 208.7ms\n",
      "Speed: 3.1ms preprocess, 208.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train211\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest030_x264_7640.png: 640x640 1 NormalVideos, 172.2ms\n",
      "Speed: 2.9ms preprocess, 172.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train212\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest039_x264_3040.png: 640x640 1 NormalVideos, 159.7ms\n",
      "Speed: 14.1ms preprocess, 159.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train213\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest024_x264_540.png: 640x640 2 NormalVideoss, 199.5ms\n",
      "Speed: 3.3ms preprocess, 199.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train214\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest039_x264_13980.png: 640x640 1 NormalVideos, 182.7ms\n",
      "Speed: 3.4ms preprocess, 182.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train215\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest030_x264_5350.png: 640x640 1 NormalVideos, 198.0ms\n",
      "Speed: 2.9ms preprocess, 198.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train216\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Arrest/Arrest039_x264_8360.png: 640x640 1 NormalVideos, 210.5ms\n",
      "Speed: 3.1ms preprocess, 210.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Arrest/yolo_ucf_train217\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Abuse/Abuse030_x264_750.png: 640x640 1 NormalVideos, 366.2ms\n",
      "Speed: 6.1ms preprocess, 366.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Abuse/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Robbery/Robbery137_x264_2060.png: 640x640 1 NormalVideos, 266.7ms\n",
      "Speed: 8.7ms preprocess, 266.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Robbery/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Robbery/Robbery048_x264_470.png: 640x640 1 NormalVideos, 314.8ms\n",
      "Speed: 3.3ms preprocess, 314.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Robbery/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Robbery/Robbery050_x264_150.png: 640x640 1 NormalVideos, 323.5ms\n",
      "Speed: 2.9ms preprocess, 323.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Robbery/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault006_x264_6730.png: 640x640 1 NormalVideos, 357.4ms\n",
      "Speed: 3.2ms preprocess, 357.4ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault010_x264_12930.png: 640x640 1 NormalVideos, 326.2ms\n",
      "Speed: 6.6ms preprocess, 326.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault010_x264_4980.png: 640x640 1 NormalVideos, 270.9ms\n",
      "Speed: 10.9ms preprocess, 270.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault011_x264_70.png: 640x640 1 NormalVideos, 242.4ms\n",
      "Speed: 4.7ms preprocess, 242.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train24\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault006_x264_360.png: 640x640 1 NormalVideos, 255.0ms\n",
      "Speed: 7.1ms preprocess, 255.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train25\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault010_x264_1150.png: 640x640 1 NormalVideos, 206.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 5.2ms preprocess, 206.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train26\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault010_x264_9310.png: 640x640 1 NormalVideos, 260.8ms\n",
      "Speed: 2.8ms preprocess, 260.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train27\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault006_x264_4760.png: 640x640 1 NormalVideos, 231.3ms\n",
      "Speed: 5.9ms preprocess, 231.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train28\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault006_x264_5020.png: 640x640 1 NormalVideos, 201.5ms\n",
      "Speed: 8.3ms preprocess, 201.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train29\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault006_x264_2200.png: 640x640 1 NormalVideos, 191.3ms\n",
      "Speed: 3.1ms preprocess, 191.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train210\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault010_x264_2380.png: 640x640 1 NormalVideos, 243.4ms\n",
      "Speed: 3.5ms preprocess, 243.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train211\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault006_x264_1080.png: 640x640 1 NormalVideos, 236.4ms\n",
      "Speed: 3.7ms preprocess, 236.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train212\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault010_x264_3060.png: 640x640 1 NormalVideos, 228.2ms\n",
      "Speed: 3.9ms preprocess, 228.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train213\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Assault/Assault010_x264_1270.png: 640x640 1 NormalVideos, 143.4ms\n",
      "Speed: 7.7ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Assault/yolo_ucf_train214\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_10200.png: 640x640 1 NormalVideos, 204.9ms\n",
      "Speed: 4.9ms preprocess, 204.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train2\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting010_x264_480.png: 640x640 1 NormalVideos, 210.2ms\n",
      "Speed: 4.8ms preprocess, 210.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train22\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_16710.png: 640x640 1 NormalVideos, 165.6ms\n",
      "Speed: 3.3ms preprocess, 165.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train23\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting033_x264_1260.png: 640x640 1 NormalVideos, 196.1ms\n",
      "Speed: 4.8ms preprocess, 196.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train24\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_16060.png: 640x640 1 NormalVideos, 193.3ms\n",
      "Speed: 6.2ms preprocess, 193.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train25\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting024_x264_500.png: 640x640 1 NormalVideos, 185.8ms\n",
      "Speed: 3.1ms preprocess, 185.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train26\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting011_x264_3030.png: 640x640 1 NormalVideos, 195.1ms\n",
      "Speed: 3.8ms preprocess, 195.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train27\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting019_x264_1850.png: 640x640 1 NormalVideos, 207.2ms\n",
      "Speed: 13.9ms preprocess, 207.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train28\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_12200.png: 640x640 1 NormalVideos, 173.1ms\n",
      "Speed: 2.8ms preprocess, 173.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train29\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting037_x264_60.png: 640x640 2 NormalVideoss, 158.7ms\n",
      "Speed: 3.1ms preprocess, 158.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train210\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_19910.png: 640x640 1 NormalVideos, 145.5ms\n",
      "Speed: 5.2ms preprocess, 145.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train211\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting046_x264_3020.png: 640x640 1 NormalVideos, 220.7ms\n",
      "Speed: 6.8ms preprocess, 220.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train212\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting033_x264_3170.png: 640x640 1 NormalVideos, 197.8ms\n",
      "Speed: 3.4ms preprocess, 197.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train213\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_11550.png: 640x640 1 NormalVideos, 161.1ms\n",
      "Speed: 2.8ms preprocess, 161.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train214\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting046_x264_2260.png: 640x640 1 NormalVideos, 194.3ms\n",
      "Speed: 6.9ms preprocess, 194.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train215\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_10710.png: 640x640 1 NormalVideos, 194.6ms\n",
      "Speed: 2.7ms preprocess, 194.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train216\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting034_x264_540.png: 640x640 1 NormalVideos, 163.8ms\n",
      "Speed: 3.0ms preprocess, 163.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train217\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting015_x264_1090.png: 640x640 1 NormalVideos, 163.1ms\n",
      "Speed: 5.2ms preprocess, 163.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train218\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting022_x264_4010.png: 640x640 1 NormalVideos, 190.0ms\n",
      "Speed: 3.8ms preprocess, 190.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train219\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting033_x264_1210.png: 640x640 1 NormalVideos, 154.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 52.4ms preprocess, 154.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train220\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting019_x264_1790.png: 640x640 1 NormalVideos, 150.6ms\n",
      "Speed: 11.2ms preprocess, 150.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train221\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting047_x264_4560.png: 640x640 1 NormalVideos, 165.5ms\n",
      "Speed: 3.0ms preprocess, 165.5ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train222\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting047_x264_4010.png: 640x640 1 NormalVideos, 243.8ms\n",
      "Speed: 7.4ms preprocess, 243.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train223\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting015_x264_1700.png: 640x640 1 NormalVideos, 235.0ms\n",
      "Speed: 8.4ms preprocess, 235.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train224\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting015_x264_430.png: 640x640 1 NormalVideos, 168.6ms\n",
      "Speed: 3.0ms preprocess, 168.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train225\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_21660.png: 640x640 1 NormalVideos, 228.9ms\n",
      "Speed: 43.5ms preprocess, 228.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train226\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting033_x264_820.png: 640x640 1 NormalVideos, 260.4ms\n",
      "Speed: 4.0ms preprocess, 260.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train227\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_2250.png: 640x640 1 NormalVideos, 357.2ms\n",
      "Speed: 4.5ms preprocess, 357.2ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train228\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_16780.png: 640x640 1 NormalVideos, 266.7ms\n",
      "Speed: 14.2ms preprocess, 266.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train229\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_21460.png: 640x640 1 NormalVideos, 292.5ms\n",
      "Speed: 14.3ms preprocess, 292.5ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train230\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_710.png: 640x640 1 NormalVideos, 262.0ms\n",
      "Speed: 10.0ms preprocess, 262.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train231\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting021_x264_110.png: 640x640 1 NormalVideos, 217.1ms\n",
      "Speed: 4.1ms preprocess, 217.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train232\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting047_x264_1860.png: 640x640 1 NormalVideos, 252.7ms\n",
      "Speed: 3.9ms preprocess, 252.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train233\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting013_x264_20.png: 640x640 1 NormalVideos, 292.0ms\n",
      "Speed: 8.7ms preprocess, 292.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train234\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting048_x264_2130.png: 640x640 1 NormalVideos, 276.2ms\n",
      "Speed: 5.9ms preprocess, 276.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train235\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting013_x264_480.png: 640x640 1 NormalVideos, 258.7ms\n",
      "Speed: 7.7ms preprocess, 258.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train236\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting028_x264_1600.png: 640x640 1 NormalVideos, 163.4ms\n",
      "Speed: 9.6ms preprocess, 163.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train237\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting026_x264_1270.png: 640x640 1 NormalVideos, 168.3ms\n",
      "Speed: 6.3ms preprocess, 168.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train238\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting048_x264_760.png: 640x640 1 NormalVideos, 206.1ms\n",
      "Speed: 7.9ms preprocess, 206.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train239\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting032_x264_15160.png: 640x640 1 NormalVideos, 227.1ms\n",
      "Speed: 2.8ms preprocess, 227.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train240\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting033_x264_2160.png: 640x640 1 NormalVideos, 155.0ms\n",
      "Speed: 3.3ms preprocess, 155.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train241\u001b[0m\n",
      "\n",
      "image 1/1 /Users/rukmini/Documents/Project/newdata/reduced_test/Shooting/Shooting019_x264_540.png: 640x640 1 NormalVideos, 177.2ms\n",
      "Speed: 3.1ms preprocess, 177.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtest_results/Shooting/yolo_ucf_train242\u001b[0m\n",
      "Training, validation, and inference completed.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "train_path = \"/Users/rukmini/Documents/Project/newdata/reduced_train\"\n",
    "test_path = \"/Users/rukmini/Documents/Project/newdata/reduced_test\"\n",
    "\n",
    "\n",
    "\n",
    "def create_yaml_file():\n",
    "    \"\"\"Creates a dataset.yaml file for YOLO training.\"\"\"\n",
    "    yaml_content = f\"\"\"\n",
    "    train: {train_path}\n",
    "    val: {test_path}/\n",
    "\n",
    "    nc: {len(os.listdir(train_path))}  # Number of classes\n",
    "    names: {os.listdir(train_path)}\n",
    "    \"\"\"\n",
    "    with open(\"ucf_dataset.yaml\", \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "\n",
    "\n",
    "\n",
    "def generate_dummy_labels(image_folder):\n",
    "    \"\"\"Generates dummy label files for images in the specified folder.\"\"\"\n",
    "    for class_folder in os.listdir(image_folder):\n",
    "        class_path = os.path.join(image_folder, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        class_id = os.listdir(image_folder).index(class_folder)\n",
    "\n",
    "        for img_file in os.listdir(class_path):\n",
    "            if img_file.endswith(\".png\"):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                label_file = os.path.splitext(img_path)[0] + \".txt\"\n",
    "\n",
    "                # Generate a dummy label (e.g., full image bounding box)\n",
    "                dummy_label = f\"{class_id} 0.5 0.5 1.0 1.0\\n\"\n",
    "\n",
    "                with open(label_file, \"w\") as f:\n",
    "                    f.write(dummy_label)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Create the YAML file for the dataset\n",
    "create_yaml_file()\n",
    "\n",
    "# Step 3: Generate dummy labels\n",
    "generate_dummy_labels(train_path)\n",
    "generate_dummy_labels(test_path)\n",
    "\n",
    "# Step 4: Load the YOLO model\n",
    "# You can download a pretrained model or use a custom model\n",
    "model = YOLO(\"yolov8n.pt\")  # Replace with 'yolov8s.pt', 'yolov8m.pt', etc., for different model sizes\n",
    "\n",
    "# Step 5: Train the model\n",
    "model.train(data=\"ucf_dataset.yaml\", epochs=3, imgsz=640, batch=16, project=\"ucf_project\", name=\"yolo_ucf_train\")\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "results = model.val(data=\"ucf_dataset.yaml\")  # Validation on test set\n",
    "\n",
    "# Step 7: Inference on test videos\n",
    "def predict_on_test_set(test_folder, model_path):\n",
    "    \"\"\"Runs inference on the test folder.\"\"\"\n",
    "    results_dir = \"test_results\"\n",
    "    if os.path.exists(results_dir):\n",
    "        shutil.rmtree(results_dir)\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "    for class_folder in os.listdir(test_folder):\n",
    "        class_path = os.path.join(test_folder, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        output_class_dir = os.path.join(results_dir, class_folder)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "        for img_file in os.listdir(class_path):\n",
    "            if img_file.endswith(\".png\"):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                result = model.predict(source=img_path, save=True, project=output_class_dir)\n",
    "\n",
    "# Run inference\n",
    "predict_on_test_set(test_folder=test_path, model_path=\"ucf_project/yolo_ucf_train/weights/best.pt\")\n",
    "\n",
    "print(\"Training, validation, and inference completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f82e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c61a286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd444e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.49 ðŸš€ Python-3.10.9 torch-2.5.1 MPS (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=ucf_dataset.yaml, epochs=5, time=None, patience=100, batch=8, imgsz=416, save=True, save_period=-1, cache=False, device=mps, workers=8, project=ucf_project, name=yolo_ucf_train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=ucf_project/yolo_ucf_train2\n",
      "Overriding model.yaml nc=80 with nc=16\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ucf_project/yolo_ucf_train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/rukmini/Documents/Project/newdata/reduced_train/Abuse.cac\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/rukmini/Documents/Project/newdata/reduced_test/Abuse.cache.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to ucf_project/yolo_ucf_train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mucf_project/yolo_ucf_train2\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      3.21G     0.8105       3.67      1.372         27        416:  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 'yolov8n' for fast performance; replace with 'yolov5n.pt' if needed\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Step 4: Train the model with optimized parameters\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mucf_dataset.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m416\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mucf_project\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolo_ucf_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Step 5: Evaluate the model\u001b[39;00m\n\u001b[1;32m     57\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mucf_dataset.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Use MPS backend\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/engine/model.py:806\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/engine/trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/engine/trainer.py:380\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    379\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/nn/tasks.py:111\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/nn/tasks.py:293\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[1;32m    292\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/utils/loss.py:234\u001b[0m, in \u001b[0;36mv8DetectionLoss.__call__\u001b[0;34m(self, preds, batch)\u001b[0m\n\u001b[1;32m    230\u001b[0m pred_bboxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_decode(anchor_points, pred_distri)  \u001b[38;5;66;03m# xyxy, (b, h*w, 4)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# dfl_conf = pred_distri.view(batch_size, -1, 4, self.reg_max).detach().softmax(-1)\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# dfl_conf = (dfl_conf.amax(-1).mean(-1) + dfl_conf.amax(-1).amin(-1)) / 2\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m _, target_bboxes, target_scores, fg_mask, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massigner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pred_scores.detach().sigmoid() * 0.8 + dfl_conf.unsqueeze(-1) * 0.2,\u001b[39;49;00m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_bboxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstride_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43manchor_points\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstride_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgt_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_gt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m target_scores_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(target_scores\u001b[38;5;241m.\u001b[39msum(), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Cls loss\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# loss[1] = self.varifocal_loss(pred_scores, target_scores, target_labels) / target_scores_sum  # VFL way\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/utils/tal.py:74\u001b[0m, in \u001b[0;36mTaskAlignedAssigner.forward\u001b[0;34m(self, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     66\u001b[0m         torch\u001b[38;5;241m.\u001b[39mfull_like(pd_scores[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbg_idx),\n\u001b[1;32m     67\u001b[0m         torch\u001b[38;5;241m.\u001b[39mzeros_like(pd_bboxes),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m         torch\u001b[38;5;241m.\u001b[39mzeros_like(pd_scores[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manc_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_gt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mOutOfMemoryError:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# Move tensors to CPU, compute, then move back to original device\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/utils/tal.py:102\u001b[0m, in \u001b[0;36mTaskAlignedAssigner._forward\u001b[0;34m(self, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Compute the task-aligned assignment. Reference code is available at\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    https://github.com/Nioolek/PPYOLOE_pytorch/blob/master/ppyoloe/assigner/tal_assigner.py.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        target_gt_idx (Tensor): shape(bs, num_total_anchors)\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     mask_pos, align_metric, overlaps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pos_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpd_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manc_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_gt\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     target_gt_idx, fg_mask, mask_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_highest_overlaps(mask_pos, overlaps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_max_boxes)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# Assigned target\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/utils/tal.py:124\u001b[0m, in \u001b[0;36mTaskAlignedAssigner.get_pos_mask\u001b[0;34m(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt)\u001b[0m\n\u001b[1;32m    122\u001b[0m mask_in_gts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_candidates_in_gts(anc_points, gt_bboxes)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Get anchor_align metric, (b, max_num_obj, h*w)\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m align_metric, overlaps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_box_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_in_gts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask_gt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Get topk_metric mask, (b, max_num_obj, h*w)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m mask_topk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_topk_candidates(align_metric, topk_mask\u001b[38;5;241m=\u001b[39mmask_gt\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopk)\u001b[38;5;241m.\u001b[39mbool())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/utils/tal.py:148\u001b[0m, in \u001b[0;36mTaskAlignedAssigner.get_box_metrics\u001b[0;34m(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_gt)\u001b[0m\n\u001b[1;32m    146\u001b[0m pd_boxes \u001b[38;5;241m=\u001b[39m pd_bboxes\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_max_boxes, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[mask_gt]\n\u001b[1;32m    147\u001b[0m gt_boxes \u001b[38;5;241m=\u001b[39m gt_bboxes\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, na, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[mask_gt]\n\u001b[0;32m--> 148\u001b[0m overlaps[mask_gt] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miou_calculation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_boxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd_boxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m align_metric \u001b[38;5;241m=\u001b[39m bbox_scores\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha) \u001b[38;5;241m*\u001b[39m overlaps\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m align_metric, overlaps\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/utils/tal.py:155\u001b[0m, in \u001b[0;36mTaskAlignedAssigner.iou_calculation\u001b[0;34m(self, gt_bboxes, pd_bboxes)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miou_calculation\u001b[39m(\u001b[38;5;28mself\u001b[39m, gt_bboxes, pd_bboxes):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;124;03m\"\"\"IoU calculation for horizontal bounding boxes.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbbox_iou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxywh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCIoU\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ultralytics/utils/metrics.py:123\u001b[0m, in \u001b[0;36mbbox_iou\u001b[0;34m(box1, box2, xywh, GIoU, DIoU, CIoU, eps)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CIoU:  \u001b[38;5;66;03m# https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     v \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m ((w2 \u001b[38;5;241m/\u001b[39m h2)\u001b[38;5;241m.\u001b[39matan() \u001b[38;5;241m-\u001b[39m (w1 \u001b[38;5;241m/\u001b[39m h1)\u001b[38;5;241m.\u001b[39matan())\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    124\u001b[0m         alpha \u001b[38;5;241m=\u001b[39m v \u001b[38;5;241m/\u001b[39m (v \u001b[38;5;241m-\u001b[39m iou \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m eps))\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iou \u001b[38;5;241m-\u001b[39m (rho2 \u001b[38;5;241m/\u001b[39m c2 \u001b[38;5;241m+\u001b[39m v \u001b[38;5;241m*\u001b[39m alpha)  \u001b[38;5;66;03m# CIoU\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py:154\u001b[0m, in \u001b[0;36m_NoParamDecoratorContextManager.__new__\u001b[0;34m(cls, orig_func)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_NoParamDecoratorContextManager\u001b[39;00m(_DecoratorContextManager):\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124;03m\"\"\"Allow a context manager to be used as a decorator without parentheses.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, orig_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m orig_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "train_path = \"/Users/rukmini/Documents/Project/newdata/reduced_train\"\n",
    "test_path = \"/Users/rukmini/Documents/Project/newdata/reduced_test\"\n",
    "\n",
    "def create_yaml_file():\n",
    "    \"\"\"Creates a dataset.yaml file for YOLO training.\"\"\"\n",
    "    yaml_content = f\"\"\"\n",
    "    train: {train_path}\n",
    "    val: {test_path}/\n",
    "\n",
    "    nc: {len(os.listdir(train_path))}  # Number of classes\n",
    "    names: {os.listdir(train_path)}\n",
    "    \"\"\"\n",
    "    with open(\"ucf_dataset.yaml\", \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "\n",
    "\n",
    "def generate_dummy_labels(image_folder):\n",
    "    \"\"\"Generates dummy label files for images in the specified folder.\"\"\"\n",
    "    for class_folder in os.listdir(image_folder):\n",
    "        class_path = os.path.join(image_folder, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        class_id = os.listdir(image_folder).index(class_folder)\n",
    "\n",
    "        for img_file in os.listdir(class_path):\n",
    "            if img_file.endswith(\".png\"):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                label_file = os.path.splitext(img_path)[0] + \".txt\"\n",
    "\n",
    "                # Generate a dummy label (e.g., full image bounding box)\n",
    "                dummy_label = f\"{class_id} 0.5 0.5 1.0 1.0\\n\"\n",
    "\n",
    "                with open(label_file, \"w\") as f:\n",
    "                    f.write(dummy_label)\n",
    "\n",
    "\n",
    "# Step 1: Create the YAML file for the dataset\n",
    "create_yaml_file()\n",
    "\n",
    "# Step 2: Generate dummy labels\n",
    "generate_dummy_labels(train_path)\n",
    "generate_dummy_labels(test_path)\n",
    "\n",
    "# Step 3: Load a lightweight YOLO model\n",
    "# Use the nano version for better performance on M2\n",
    "model = YOLO(\"yolov8n.pt\")  # 'yolov8n' for fast performance; replace with 'yolov5n.pt' if needed\n",
    "\n",
    "# Step 4: Train the model with optimized parameters\n",
    "model.train(data=\"ucf_dataset.yaml\", epochs=5, imgsz=416, batch=8, project=\"ucf_project\", name=\"yolo_ucf_train\", device=\"mps\")\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "results = model.val(data=\"ucf_dataset.yaml\", device=\"mps\")  # Use MPS backend\n",
    "\n",
    "# Step 6: Inference on test set\n",
    "def predict_on_test_set(test_folder, model_path):\n",
    "    \"\"\"Runs inference on the test folder.\"\"\"\n",
    "    results_dir = \"test_results\"\n",
    "    if os.path.exists(results_dir):\n",
    "        shutil.rmtree(results_dir)\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "    for class_folder in os.listdir(test_folder):\n",
    "        class_path = os.path.join(test_folder, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        output_class_dir = os.path.join(results_dir, class_folder)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "        for img_file in os.listdir(class_path):\n",
    "            if img_file.endswith(\".png\"):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                result = model.predict(source=img_path, save=True, project=output_class_dir, device=\"mps\")\n",
    "\n",
    "# Step 7: Run inference\n",
    "predict_on_test_set(test_folder=test_path, model_path=\"ucf_project/yolo_ucf_train/weights/best.pt\")\n",
    "\n",
    "print(\"Training, validation, and inference completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb65b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
